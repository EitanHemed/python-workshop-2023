{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Python-Workshop-Day-1.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyMPvM2a/auVwaNqAiP9If9Q"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <center><u>Introduction to data analysis using Python<u></center>\n",
    "### <center>July 16-17th, 2023</center>\n",
    "### <center>Eitan Hemed, PhD</center>\n",
    "### <center>Department of Psychology, University of Haifa</center>\n",
    "\n",
    "\n",
    "---\n",
    "<p align=\"center\">\n",
    " <b> All materials and exercise solutions are available on </b>\n",
    "<a style=\"font-weight:bold\" href=\"https://github.com/EitanHemed/python-workshop-2023\">Github</a>\n",
    "</p>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the previous part we got to know the fundamentals of Python. In the rest of the workshop, we'll begin our introduction to data analysis using Python. We'll begin by how data is organized and manipulated, how to plot our data and finally how to run common statistical tests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NumPy\n",
    "\n",
    "NumPy (\"Numerical Python\") is not part of the standard library, meaning that this is a package that you need to install (specifically on Google Colab, it was already installed for you). However, it  is fundemental to almost all Python packages used for scientific or data-related work (espcially when working with small to medium-sized data). NumPy is used in other packages dedicated to wrangling and organizing data, plotting data, analyzing data and many more (see [here](https://numpy.org/)).\n",
    "\n",
    "----\n",
    "\n",
    "Aside from many mathematical functions, NumPy provides a data structure called an array.\n",
    "\n",
    "NumPy Arrays (called N-Dimensional arrays, or ndarray for short), NumPy arrays are an ordered mutable collections, that are intended for numerical computation. As the name implies they can be of any number of dimensions (1D, 2D, 3D, up to 32D at the moment).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![](https://www.physicsforums.com/attachments/1614347010838-png.278712/)\n",
    "\n",
    "[image source](https://www.physicsforums.com/attachments/1614347010838-png.278712/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To begin using NumPy, we first have to import it. The common alias for importing NumPy is the following:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BF2CCT9Nebf2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633105523531,
     "user_tz": -180,
     "elapsed": 600,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "b47cdcf0-06d4-4d2c-b8b9-a62c44e99a96"
   },
   "source": [
    "import numpy as np"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a 1-d array:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 5 ])\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although our array looks like a plain list. NumPy arrays have many features that makes them more useful than lists in many cases. For example, scaler and vector operations out of the box:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 5 ])\n",
    "print(a + 2,\n",
    "      a ** a, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Built-in methods for common operations:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(a.mean(), a.std())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnYwh8jFgP4H"
   },
   "source": [
    "You might have heard that Python is a readable language at the expanse of execution speed. However, NumPy is much faster than vanilla Python, sometimes by orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yt1-vyFpgZDY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633105896496,
     "user_tz": -180,
     "elapsed": 13250,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "d3eb14da-544e-4c3f-e073-adaa3cbd7c4d"
   },
   "source": [
    "_array = np.arange(1e5) # An array with all integers between 0 and 100,000 (end-exclusive)\n",
    "_list = list(range(int(1e5))) # A list with all integers between 0 and 100,000 (end-exclusive)\n",
    "\n",
    "print(\"Vanilla Python: \")\n",
    "%timeit sum(_list)\n",
    "\n",
    "print(\"NumPy: \")\n",
    "%timeit np.sum(_array)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHQL41z-ke0u"
   },
   "source": [
    "One of the reasons that NumPy is very fast has to do with how memory is allocated for Python objects vs. NumPy arrays. an store only a single type of values in an array. Objects are coerced into a different data type to fit the most 'complex' type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Vh14pmMkxc1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633106079488,
     "user_tz": -180,
     "elapsed": 336,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "6ad1b241-0bcc-4cec-e8bf-92c9c5539ffa"
   },
   "source": [
    "a = np.full(5, True)\n",
    "print(a) # all elements are booleans\n",
    "a[-1] = 0\n",
    "print(a) # the last element is coerced into a boolean as well"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byi9x2TltoUA"
   },
   "source": [
    "The same goes for strings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTzaXe10sZKi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633106496808,
     "user_tz": -180,
     "elapsed": 325,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "fee5c29c-f9ac-4e1f-b6f6-e26e1a4eccb1"
   },
   "source": [
    "a = np.linspace(start=-5, stop=5, num=10).round(2) # Get evenly spaced numbers\n",
    "print(a, a.dtype) # the default type is float\n",
    "a[3:5] = ['105.3', '7.7']\n",
    "print(a, a.dtype) # the 4th and 5th elements are coerced into floats."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc_mXjwkvHqN"
   },
   "source": [
    "#### Shape and indexing.\n",
    "\n",
    "NumPy arrays can contain be built across multiple dimensions. This allows us to create complex and flexible data structure.\n",
    "\n",
    "Let's create an array with two dimensions - 3 rows and 4 columns. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4ZUNGl6w2JD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633107334237,
     "user_tz": -180,
     "elapsed": 331,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "8daec97b-4d4c-4a56-b7a2-adb80d0f2140"
   },
   "source": [
    "three_by_four = np.ones(shape=(3, 4)) # (y, x)\n",
    "print(three_by_four,\n",
    "      \"\\nThe shape is: \", three_by_four.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "One thing you need to get used to is that the first dimension is the rows, and the second is the columns (Y, X). This is the opposite of how we usually think about matrices (X, Y)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRfA4SDXx8-Q"
   },
   "source": [
    "Now we can begin selecting the array elements using both dimensions. Indexing of arrays with complex shapes is a breeze. \n",
    "\n",
    "Here we select the first and third rows (`0::2`), and all columns except the first (`1:`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqkd1BPHx1JV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633107577273,
     "user_tz": -180,
     "elapsed": 422,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "7d527ac9-cf7e-4301-c607-54b0849b651d"
   },
   "source": [
    "three_by_four[0::2, 1:] = 0\n",
    "print(three_by_four)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sB38DishzHnf"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "We can change the shape of an array using the `reshape` method. First, create an array of the values 1 through 48 using `np.arange`. Then, reshape it into a different shape with 3 or more dimensions.\n",
    "\n",
    "Note that in order to fit all elements the *product of the size of all axis* must equal the *total number of elements in the array*."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jYgAGDgCyf_A"
   },
   "source": [
    "a = np.arange(1, 49)\n",
    "print(a.shape)\n",
    "\n",
    "a = a.reshape(3, 4, 4)\n",
    "print(\"The new shape is:\", a.shape)\n",
    "print(\"The product of the dimensions is:\", np.product(a.shape))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "One useful wildcard in reshaping is `-1`. This wildcard tells NumPy to infer the size of the axis from the other axes.\n",
    "\n",
    "Repeat the exercise above, now reshaping the array into any 3D shape, but use `-1` anywhere in the `reshape` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.arange(0, 36)\n",
    "print(\"Elements in a:\", a.size)\n",
    "\n",
    "a = a.reshape(-1, 3, 4)\n",
    "print(\"The new shape of a is:\", a.shape)\n",
    "print(\"The product of the dimensions is:\", np.product(a.shape))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One thing to mention regarding arrays shapes, is that they control our ability to work with different arrays. We've seen that we can add or multiply all values of an array in a scaler, or add a similar shaped array to another. But what happens when we try to add two arrays with different shapes?\n",
    "\n",
    "Numpy requires that shapes will match in the following fashion - either the size of a dimension is 1, or it is the same size as the other array. If the two arrays have different number of dimensions, then NumPy tries to match them beginning from the last dimension and proceeding backwards."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.ones(shape=(3, 4))\n",
    "b = np.ones(shape=(5, 5, 3, 4))\n",
    "print(a + b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the shapes of the two arrays do not match, consider reshaping them to match. If that's not possible due to the number of elements you could possibly pad the arrays with some values to make them match. If you happen to work with images, you will see that this is a common practice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boolean Indexing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFSTX90Jqogi"
   },
   "source": [
    "Another thing we will touch upon regarding NumPy array is Boolean Indexing. In boolean indexing we are using truth values to index an array. When NumPy arrays are checked for their truth values they (usually) return the value for each element. This is not especially complicated but it is a crucial topic when working with data frames, covered later. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "d1CtbKbqfxNm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633359942152,
     "user_tz": -180,
     "elapsed": 316,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "8953f5e5-418a-4749-853e-2bc8432e833e"
   },
   "source": [
    "x = np.array([-1, -15, 17, -7, 256]) # Use a list to create an array\n",
    "boolean_indices_of_positive_values_in_x = x > -1\n",
    "print(\"Positive values:\", boolean_indices_of_positive_values_in_x)\n",
    "print(x[boolean_indices_of_positive_values_in_x])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Create an array of 10 numbers, and use `np.where` to find the *indices* of the positive values in the array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = np.arange(-5, 5)\n",
    "print(np.where(a > 0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JSPjHns01Fq"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Create a 5 (rows) by 7 (columns) array of random numbers. Here we use the NumPy `random` module, to create an array from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMraKkmzuBnd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633361899405,
     "user_tz": -180,
     "elapsed": 405,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "44e25394-c036-4f4b-e63d-07f78de45632"
   },
   "source": [
    "np.random.seed(42) # So we would get the same numbers on each run.\n",
    "five_by_seven = np.random.random_sample(size=(5, 7))\n",
    "print(five_by_seven)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiply the array by 100 and round the values to 2 decimal points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "five_by_seven = (five_by_seven * 100).round(2) # or use np.round(a, d)\n",
    "print(five_by_seven)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select all rows and the first 3 columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(five_by_seven[:, :3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate the array by taking the maximum value along all rows (axis 0), in order to get the maximum value on each column (axis 1). How many values should you expect to get?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(five_by_seven.max(axis=0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate the array by finding the median value of each row. How many values should you expect to get?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display vals min along rows (aggregating on columns)\n",
    "print(np.median(five_by_seven, axis=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4m-oTTF7a6x"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Using the `five_by_seven` array, find the values that are greater than 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dr-KKatn7W4X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633361962951,
     "user_tz": -180,
     "elapsed": 326,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "2beffbe1-8951-40d0-8e83-2839478dfb14"
   },
   "source": [
    "five_by_seven[five_by_seven > 50]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Using the `five_by_seven` array, find the values that are greater than 50, and less than 70."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "five_by_seven[(five_by_seven > 50) & (five_by_seven < 70)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Now, find the indices of the values that are greater than 50, and less than 70."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices_of_target_values_on_all_columns = np.argwhere((five_by_seven > 50) & (five_by_seven < 70))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Rows and columns\n",
    "print(indices_of_target_values_on_all_columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Continue by selecting only the values that are on the first and last columns, but do not exclude any rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_values_on_relevant_columns = np.isin(indices_of_target_values_on_all_columns[:, 1], [0, 6])\n",
    "target_values_on_relevant_columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now use the (row, column) indices to change the values to np.nan\n",
    "indices_of_target_values_to_modify = indices_of_target_values_on_all_columns[target_values_on_relevant_columns]\n",
    "five_by_seven[indices_of_target_values_to_modify[:, 0],\n",
    "    indices_of_target_values_to_modify[:, 1]] = np.nan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "five_by_seven"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`np.nan` is a special value that represents \"Not a Number\". It is used to represent missing values in NumPy arrays. If you want NumPy to ignore `np.nan` values, you can use predefined functions that do so, such as `np.nanmax`, `np.nanmin`, `np.nanmean` etc. If you do not use these functions, you will get `np.nan` as a result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(np.max(five_by_seven), np.nanmax(five_by_seven))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use `np.isnan` to find the indices of the `np.nan` values, and exclude them, or replace them with a different value."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Use `np.isnan` to find the indices of the `np.nan` values, and replace them with the mean value of the array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "five_by_seven[np.isnan(five_by_seven)] = np.nanmean(five_by_seven)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Print the proportion of NaN values in the array, using `np.isnan`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.isnan(five_by_seven).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NumPy contains many more functionalities than what we covered here. However, if you have a good grasp on the basics of working with arrays (broadcasting, shapes, boolean indexing, etc.), you should be able to begin utilizing NumPy in your work, as we'll see in the next sections."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haQlW0Hm98fg"
   },
   "source": [
    "# Matplotlib\n",
    "\n",
    "Matplotlib is the major library for scientific plotting in Python, that serves as backend to more high-level plotting libraries (one of them we'll use later). \n",
    "Naturally (and espcially if you ever used MatLab), you would want to use matplotlib like it is used below. However, Matplotlib offers a much more flexible way to draw plots, which we'll learn on this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "c2jk0azRE41I",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633365900598,
     "user_tz": -180,
     "elapsed": 24,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "aa91258f-1c8c-495e-9a0a-3ba46102da3c"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = np.arange(0, 16)\n",
    "b = np.power(a, 2)\n",
    "\n",
    "plt.scatter(a, b)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9pEy-0VGmBe"
   },
   "source": [
    "The recommended way to use Matplotlib is by interacting with objects. This can give you fine-grained control, and better code modularity.\n",
    "\n",
    "A figure is similar to an image - a collection of (usually) one or more axes. Axes are what you would usually call plots - a painted region with some associated data. Axes contain the plots we would draw - lineplots, scatterplots, boxplots etc.\n",
    "\n",
    "---\n",
    "\n",
    "![image source](https://matplotlib.org/stable/_images/sphx_glr_anatomy_001_2_00x.png)\n",
    "\n",
    "[image source](https://matplotlib.org/stable/gallery/showcase/anatomy.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "This is the common idiom for creating an axes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "3kNdFekgGJPn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633365302978,
     "user_tz": -180,
     "elapsed": 317,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "bd512c13-9606-420a-be93-369be8a15090"
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# We can change the figure parameters\n",
    "fig.set_facecolor('royalblue')\n",
    "\n",
    "# We can change the ax parameters\n",
    "ax.set(xlabel='This is X', ylabel='This is Y', xlim=[0, 30],\n",
    "       ylim=[0, 500])\n",
    "\n",
    "# We can draw objects into ax, controlling the drawing specs\n",
    "ax.scatter(a, b, c='red', marker='v')\n",
    "\n",
    "# And save the figure to a file\n",
    "fig.savefig('myplot.jpg', quality=100)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwADkw61KM_5"
   },
   "source": [
    "#### Multiple axes\n",
    "\n",
    "However, the real flexibility of this idiom is revealed when we want to plot over more than one axes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Z_fWRBR4KepM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633365634001,
     "user_tz": -180,
     "elapsed": 871,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "f8bd4c7d-b639-4b2e-fb83-e016d02e71ad"
   },
   "source": [
    "# axs, as we are creating more than one\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, sharey=True) \n",
    "\n",
    "print(type(axs))\n",
    "print(axs.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKuz_uhxLHCK"
   },
   "source": [
    "`axs` is actually a 2D NumPy array - rows (0) and columns (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crpIJBgwKsqj"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Create a figure with a 2 X 3 array of axes. Plot some random data on the middle axes in the lower row."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "OwS1Gx5VL6dy",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633423364585,
     "user_tz": -180,
     "elapsed": 925,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "71278e49-0201-4926-a774-6e9cda8caf4e"
   },
   "source": [
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "a = np.random.random_sample((10, ))\n",
    "\n",
    "axs[1, 1].plot(a)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXRNpxiiecWI"
   },
   "source": [
    "Often times, we want to plot different groups on different plots. The main idiom to do it is using a `for` loop with `zip`. \n",
    "\n",
    "```\n",
    "for group_data, ax in zip(all_data, axs):\n",
    "    ax.hist(group_data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "et6S-EttfGLh"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "We will simulate a small dataset, of four groups, with 20 samples for each of the groups, drawn from different normal distributions.\n",
    "\n",
    "Next we will plot a histogram of the data on four different axes, each with a different title for each group.\n",
    "\n",
    "This exercise requires some manual work and googling to find the right functions. Usually, you can find the right function by googling. For example, if you want to plot a histogram, you can google \"matplotlib histogram\" or \"numpy normal distribution\", and you will find the right function."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "7T6mvUgZfd0P",
    "executionInfo": {
     "status": "error",
     "timestamp": 1633605819374,
     "user_tz": -180,
     "elapsed": 1366,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "01f9cbf9-750b-4952-922f-e8b08ee1e287"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import sem\n",
    "\n",
    "np.random.seed(99)\n",
    "\n",
    "# Creating a figure with 2 X 2 axes, with shared x and y axes, to ensure the range of values on each plot is the same.\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "# Create a dictionary with the data for each group. Fill the Mean and std values for each group.\n",
    "data = {\n",
    "    'Group A': np.random.normal(loc=7, scale=3, size=20),\n",
    "    'Group B': np.random.normal(loc=10, scale=3, size=20),\n",
    "    'C': np.random.normal(loc=10, scale=9, size=20),\n",
    "    'D': np.random.normal(loc=20, scale=3, size=20),\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# `flat` Returns a flattened array (1D, so we can zip it with the matching keys), otherwise - we would have a 2 X 2 array\n",
    "for group_name, ax in zip(data, axs.flat):\n",
    "    \n",
    "    # Create a histogram of the values\n",
    "    ax.hist(data[group_name])\n",
    "    \n",
    "    # Mark the mean of the dataset.\n",
    "    ax.axvline(data[group_name].mean(), c='red', label='Group Mean')\n",
    "\n",
    "    # Calculate standard error of the mean and turn into 95%-CI  \n",
    "    ax.errorbar(x=data[group_name].mean(), \n",
    "                y=1,\n",
    "                xerr=1.96 * sem(data[group_name]),\n",
    "                c='black', capsize=8, elinewidth=3,\n",
    "                label='95% CI'\n",
    "                )\n",
    "\n",
    "    ax.set_title(group_name)\n",
    "\n",
    "# Add a legend only to the last ax.\n",
    "ax.legend(facecolor='silver', framealpha=1)\n",
    "\n",
    "# Removes empty \"width\" space, makes axes wider (`h_pad` for \"height\")\n",
    "fig.tight_layout(w_pad=0.2) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scc17VdGmtYD"
   },
   "source": [
    "Matplotlib has many other features and plots, we merely scratched the surface. However, unless you want super-customized plots, you can usually find a solution online and copy-paste it to your code.\n",
    "\n",
    "Here is the matplotlib [gallery of examples](https://matplotlib.org/stable/gallery/index.html), [tutorials for specific tasks](https://matplotlib.org/stable/tutorials/index.html), and a quick [styles sheet](https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html), in case you want more aesthetically pleasing plots.\n",
    "\n",
    "Some of the work we did in this section was manual and can be skipped using higher-level tools (espcially one we will cover at a later point), however it is crucial to understand the basics of matplotlib so you can take control over your plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It should be mentioned that for specific tasks and fields, there are often specialized tools. To name a few:\n",
    "* For big data, there is [Datashader](https://datashader.org/), [Holoviews](https://holoviews.org/) and [Plotly](https://plotly.com/python/).\n",
    "* For statistical plots, there is [Seaborn](https://seaborn.pydata.org/), which is built on top of matplotlib."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTyANlELsPz_"
   },
   "source": [
    "# Pandas\n",
    "\n",
    "pandas ('panel-data') is the main library for working with tabular data in Python on small data sets (as a rule of thumb, less than 1GB).\n",
    "\n",
    "Before learning how to read data into Pandas, or exporting it out of Pandas, we will get to know the main data structures in Pandas.\n",
    "\n",
    "One note about Pandas is that there is usually more than one way to do things. Depending on the context some way might be better fit than others.\n",
    "\n",
    "----\n",
    "\n",
    "The main object you will work with in Pandas is a dataframe (`pd.DataFrame`).\n",
    "A dataframe is basically a table, but it offers much more than just a 2D matrix of values.\n",
    "\n",
    "![](https://media.geeksforgeeks.org/wp-content/cdn-uploads/creating_dataframe1.png)\n",
    "\n",
    "\n",
    "([source](https://media.geeksforgeeks.org/wp-content/cdn-uploads/creating_dataframe1.png))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBsrOQaQHnt5"
   },
   "source": [
    "## pandas.Series\n",
    "\n",
    "A dataframe is composed of columns, each series is 1-D nd-array, with axis labels. We can create a series from a list of an array of values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "kzVW26aXH5Cm",
    "executionInfo": {
     "status": "error",
     "timestamp": 1633768250713,
     "user_tz": -180,
     "elapsed": 24,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "1df11738-5d9a-452a-976e-7e71a195bb95"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "student_grades = pd.Series(\n",
    "    data=np.random.normal(90, 1.5, size=5), \n",
    "    index=list('ABCDE'), name='student_grades'\n",
    ")\n",
    "print(student_grades)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Under the hood, a Series is a numpy array, with an index. We can access the values and the index separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\n",
    "    type(student_grades),\n",
    "    type(student_grades.values), sep='\\n'\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(student_grades.index, type(student_grades.index), sep='\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Create a series of floats, then access the first value and turn it into a string. Then print the series to see the change. Next, print the type of each value in the series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = pd.Series([4., 8.0, 15.0, 16.0, 23.0, 42.0])\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s[0] = \"Some float\"\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the data type of the series has changed to `object`, which is the most general type in Python. This is in contrast with NumPy arrays, which are homogenous."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the `Series.apply` method to apply a function to each value in the series, and reveal its type."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s.apply(type)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When Pandas encounters a Series with mixed data types, it will use the most general type to represent the series, which is `object`.\n",
    "However, it is not recommended to mix data types in a Series, as it can cause unexpected behavior and slows down computations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "To reverse this change, we will find the index of the value we changed, and use it to replace the value with a float."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s[s.apply(type) == str] = 4.0\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It seems that the dtype of the series is still `object`. Use the `Series.astype` method to change the dtype of the series to `float`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = s.astype(float)\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyKkobdQLrLo"
   },
   "source": [
    "## pandas.DataFrame\n",
    "\n",
    "A data frame is a collection of series objects, known as columns. Dataframes are potentially heterogeneous, unlike arrays, as each column can have its own data type(s).\n",
    "\n",
    "----\n",
    "\n",
    "We will now create a dataframe, but we will not give it any special column names (label-based identifier for columns - axis 1) or row names (index - label based\n",
    "identifier for rows - axis 0). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MDZ7i_cOCbA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633434133379,
     "user_tz": -180,
     "elapsed": 303,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "8ee73c1f-2271-4df2-ade6-881532e42ff0"
   },
   "source": [
    "# Create 5 columns of 20 values each, sampled from a random distribution\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random_numbers_df = pd.DataFrame(\n",
    "    data=np.random.normal(size=(3, 5)))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add a 6th column that contains random strings\n",
    "random_numbers_df[5] = np.random.choice(['dog', 'cat', 'bear', 'bird'],\n",
    "                                     size=random_numbers_df.shape[0])\n",
    "\n",
    "print(random_numbers_df,\n",
    "      random_numbers_df.columns,\n",
    "      random_numbers_df.index, sep='\\n\\n')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezWT_Hw5RQdD"
   },
   "source": [
    "We can get some information on our dataframe using `df.info` e.g., the numebr of null values on each column, their names and data types."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLq83TbHRNRO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633434267418,
     "user_tz": -180,
     "elapsed": 354,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "dd0fe447-dad0-4f66-82ad-b9b72b9555fc"
   },
   "source": [
    "random_numbers_df.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKBsUZ7vOw-w"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Referring to columns using an integer index doesn't add much over arrays. This is way we can use column names.\n",
    "\n",
    "Change the name of the dataframe columns using multiple ways. Print the new column names after each change to see what happened.\n",
    "*   First using assignment on creation.\n",
    "*   Second, update the column names by using the `pd.DataFrame.rename` method (e.g., change names, capitalization, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "T2pPGibqOwiS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633460377460,
     "user_tz": -180,
     "elapsed": 307,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "b9200fcd-0a68-4fcd-e800-6eaf59fa508a"
   },
   "source": [
    "column_names = ['Course', 'Term', 'Average', 'Year']\n",
    "\n",
    "data_by_terms = [\n",
    "          ('Python 101', 'Fall', 95, 2021),\n",
    "          ('Python 101', 'Spring', 85, 2020),\n",
    "          ('Python 101', 'Fall', 90, 2019),\n",
    "          ('Python 102', 'Fall', 95, 2021),\n",
    "          ('Python 102', 'Summer', 100, 2020),\n",
    "          ('Python 102', 'Fall', 90, 2019),\n",
    "    ]\n",
    "\n",
    "\n",
    "course_grades = pd.DataFrame(\n",
    "    data=data_by_terms, columns=column_names)\n",
    "\n",
    "print(course_grades)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "The columns on the dataframe are not renamed after running this cell. Can you explain why?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rename_columns_dict = dict(zip(course_grades.columns,\n",
    "             ['Course Name', 'Semester', 'Mean Grade', 'Date']))\n",
    "\n",
    "course_grades.rename(rename_columns_dict, axis=1) # can be replaced with course_grades.rename(columns=rename_columns_dict)\n",
    "\n",
    "print(course_grades)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQauZG-g03qZ"
   },
   "source": [
    "The crux of the previous exercise was that in Pandas, you have to be aware what are the effects of your actions.\n",
    "\n",
    "Many of the functions return a copy of the dataframe with the additional change from the function call, rather than change it in place by default. You can always reassing the result of the function call to the original variable, or use `inplace=True` when calling a method like `rename`. This is a matter of choice, but there are [debates](https://github.com/pandas-dev/pandas/issues/16529) for and against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP43k_wc51Nn"
   },
   "source": [
    "### Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAtLqsy6_Z9g"
   },
   "source": [
    "In pandas you can select columns, rows or both in multiple ways.\n",
    "\n",
    "To demonstrate and practice it we will load an example dataset from a library that we'll get to know later.\n",
    "The dataset is called `mpg` and contains information about cars, such as their fuel consumption, number of cylinders, etc. It can be used to show the different selection methods, as it contains both numeric and string columns."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "hyx3nZY35htv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633768292093,
     "user_tz": -180,
     "elapsed": 2844,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "ccc56efc-c774-4fa4-ccbd-599ee7584ebf"
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "mpg = sns.load_dataset('mpg')\n",
    "\n",
    "print(mpg.info())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.head(5) # prints the first 5 rows,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.describe() # prints some statistics on the numeric columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Integer-location based indexing\n",
    "\n",
    "Our first method of selecting data is using the `df.iloc` method.\n",
    "\n",
    "`iloc` stands for integer-location. We know that a dataframe is in some sense a collection of NumPy arrays, and we know how to index 2-D arrays. So we know how to use iloc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.iloc[0, -1] # This returns the first row, last column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Fill the code below to select every third row (axis=0), beginning with the third one, and every other column (axis=1) in the dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.iloc[2::3, ::2]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can also use booleans with `iloc` to select rows or columns, or mix them with integers for different axis. This is useful when you want to select rows or columns based on a condition."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #  6th row and below, only first and last columns\n",
    "mpg.iloc[5:, [True, False, False, False, False, False, False, False, True]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "iloc is flexible, but can only be fed integers. It is pretty straightforward so we won't touch it next.\n",
    "For more info take a look at the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label-based selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `loc` attribute of the dataframe can be used for label-based indexing. It can be used to retrieve single or multiple indices of rows or columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, without using `loc`, we can retrieve a single column by using its name as an attribute of the dataframe, just like we did with a single row from a series."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oYN2Hl6T4mjW"
   },
   "source": [
    "mpg['origin'].tail(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfjdEsvyCZCk"
   },
   "source": [
    "You can also use `mpg.origin` to get the same result, although alluring for newcomers, this is not recommended.\n",
    "Aside from not being the convention, this can be problematic due to the following reasons (among others):\n",
    "* You cannot retrieve a column this way if it has spaces in it (`df.total price`).\n",
    "* You cannot store the column name in another variable. (`x = 'col_name'; df.x`)\n",
    "* You cannot retrieve a couple of columns together."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZZVyBAMsC5iI"
   },
   "source": [
    "mpg[['model_year', 'weight']] # You can retrieve multiple columns in a new order"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW5XSmPoEF94"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "z2nIh_ZXEacu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633464735734,
     "user_tz": -180,
     "elapsed": 31,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "30cbaacc-e2f7-49c3-94c4-057cec38fa4a"
   },
   "source": [
    "mpg['model_year'] += 1900 # This is why reassignment works here.\n",
    "mpg.head() # The original dataframe is changed."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJRf8KMLEY4v"
   },
   "source": [
    "However, this is pretty limited. We can't use it to select rows, let alone write complex queries to get just a selected part of our data. For that we can use `loc`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TzhdUwJTJ4-g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633465981868,
     "user_tz": -180,
     "elapsed": 424,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "ef92f15b-8316-443b-d2d1-2c9235ae71b4"
   },
   "source": [
    "mpg.loc[:, ['mpg', 'model_year']] # Select all rows, only the mpg and model_year columns"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_sZhp5RNbaR"
   },
   "source": [
    "Here is a more complex example, where we want to select only Toyota Corollas from the dataset.\n",
    "Here we do it in two steps:\n",
    "1. We create a boolean series that is `True` for the rows we want to select, and `False` for the rest."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDU01_M1Nk6-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633466958993,
     "user_tz": -180,
     "elapsed": 320,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "1f3cba02-33c5-4022-9e27-20a4078b9e4c"
   },
   "source": [
    "rows_where_torolla = mpg['name'] == 'toyota corolla'"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. We use this boolean series to select the rows we want."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.loc[rows_where_torolla, ['name', 'model_year', 'origin']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Select all the Volvo and Ford entries, that are from the year 1976 or later, and are not manufactured by Japanese companies."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nE-YUenQOBj1"
   },
   "source": [
    "selected_group = mpg.loc[\n",
    "        # Select non-japanese models\n",
    "        (mpg['origin'] != 'japan') \n",
    "        # Models from 1976 or later\n",
    "        & ~(mpg['model_year'] % 1900 > 75)\n",
    "        # Find if the model name  contains 'volvo or ford'\n",
    "        & (mpg['name'].str.contains('volvo|ford')) , :] # Select all columns, or only some of them\n",
    "\n",
    "selected_group"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "`.loc` returns a copy of the dataframe, so we can modify it without changing the original dataframe. This is useful when we want to create a new dataframe from a subset of the original dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selected_group.loc[selected_group['name'].str.contains('volvo'), 'origin'] = 'sweden'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "((selected_group['origin'] == 'sweden').any(),  # Some of the car origins are from Sweden\n",
    "    (mpg['origin'] == 'sweden').any()) # None of the car origins are from Sweden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the index of the dataframe is still preserved. So we can mutate this new dataframe and still use the original index, which may contain important information (e.g., timestamps, in time-series data)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E21Wm3gtPELn"
   },
   "source": [
    "You've noticed that we didn't use the regular `and` and `not` keywords when chaining arguments. Here you are required to use bitwise-operators.\n",
    "\n",
    "The short version for what you should know is:\n",
    "* When chaining conditions use parantheses.\n",
    "* Instead of `and` use `&`\n",
    "* Instead of `or` use `|`\n",
    "* Instead of `not` use `~`\n",
    "\n",
    "If you want the long version, go [here](https://towardsdatascience.com/bitwise-operators-and-chaining-comparisons-in-pandas-d3a559487525). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rSk5iRRq0Td"
   },
   "source": [
    "### Setting and mutating\n",
    "\n",
    "There are multiple ways by which you can update existing values in the dataframe or add new. \n",
    "\n",
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "Setting with enlargement is a method in which we \"try\" to index inexistent indices and set their values. Create a new column called 'kpg' (kilometers per gallon; mpg multiplied by 1.609)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6qKS8G0pqz3m",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633512522261,
     "user_tz": -180,
     "elapsed": 322,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "32a66db5-ea8d-41ea-ad3a-ee6a6ae853fb"
   },
   "source": [
    "mpg['kpg'] = mpg['mpg'] * 1.609\n",
    "mpg.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko2dDbzLtRLb"
   },
   "source": [
    "The same goes for adding new rows. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "h4qF6zIQtW7f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633512525212,
     "user_tz": -180,
     "elapsed": 291,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "1321843b-f272-418c-ba3f-08c982f9af04"
   },
   "source": [
    "# We are using some null values for Lada, as we don't have the mpg data\n",
    "mpg.loc[mpg.shape[0]] = (\n",
    "    # mpg, cylinders, displacement, horsepower, weight, acceleration, model_year, origin, name, kpg\n",
    "    np.nan, 4, 95.69, 78, 2535.32, 23, 1977, 'soviet union', 'Lada Niva', np.nan)\n",
    "mpg.tail()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "We can also set values for a specific row and column. Set the mpg value of the Lada Niva to 10, then update the kpg value accordingly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.loc[mpg['name'] == 'Lada Niva', 'mpg'] = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.loc[mpg['name'] == 'Lada Niva', 'kpg'] = 10 * 1.609"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you've seen, we can use `loc` to update specific values in the dataframe in a flexible manner."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBUheOGn0OFy"
   },
   "source": [
    "### GroupBy\n",
    "\n",
    "\"Group by\" is a way to do one or more of the following steps: \n",
    "* Split the dataframe into groups.\n",
    "* Apply a function to each group (e.g., calculate summary statistics).\n",
    "* Recombine the results into a dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "ZE5fLeXw4rgb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633511793069,
     "user_tz": -180,
     "elapsed": 279,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "c0d58267-a895-49c2-ae28-b5d8cf6db576"
   },
   "source": [
    "# Here is a full split-apply-combine example\n",
    "mpg.groupby(['origin', 'cylinders'], as_index=True)[['horsepower', 'weight']].median()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYdynjYQ5Hv7"
   },
   "source": [
    "Let's break it down.\n",
    "\n",
    "`groupby` takes column name(s) as the keys that are used for grouping. It returns a `DataFrameGroupBy` object, which is a special view of the dataframe. It doesn't actually do anything (like aggregating) until you apply a function to it, but you can extract specific groups from it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4v25gcQY5YRQ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633513744027,
     "user_tz": -180,
     "elapsed": 366,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "994c7689-b616-49aa-df5d-c91fbbb4d001"
   },
   "source": [
    "gb = mpg.groupby('origin')\n",
    "gb.groups['japan'] # Returns the indices from the original dataframe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slPkPagX5qFB"
   },
   "source": [
    "We can grab a specific group from the groupby object:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GsQziICd5pHT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633512091012,
     "user_tz": -180,
     "elapsed": 293,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "b094761a-4f81-4b11-c9c9-70b6039b9125"
   },
   "source": [
    "usa = gb.get_group('usa')\n",
    "usa.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tCEJkkq5559"
   },
   "source": [
    "We can apply all sorts of transformations or aggregations on the group."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The mean of each numeric column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(usa.select_dtypes('number').mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The relative frequency of each non-numeric column:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GESHrSBd6Bgp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633512148132,
     "user_tz": -180,
     "elapsed": 278,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "0d6f8ef7-c26a-429b-bee4-7f5569cd4a76"
   },
   "source": [
    "print(usa.select_dtypes('object').value_counts(\n",
    "    normalize=True).mul(100).round(2).head(10), sep='\\n')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS1wy0Rx6A6x"
   },
   "source": [
    "And we can iterate over groups, which is a common matplotlib-pandas idiom."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "xB-OIssR6tXz",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633513636387,
     "user_tz": -180,
     "elapsed": 1044,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "4e275f32-9eda-47d0-9327-4f7f6a70bc2b"
   },
   "source": [
    "# First create the figure and axes\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "\n",
    "# Then plot each group in a separate axes\n",
    "for (group_name, group_df), ax in zip(gb, axs.flat):\n",
    "    # Extract the values and transpose (reshape) from (n, 2) to (2, n)\n",
    "    x, y = group_df[['acceleration', 'horsepower']].values.T\n",
    "    ax.scatter(x, y, s=10, alpha=0.5)\n",
    "    ax.set_title(group_name)\n",
    "    # For annotation, add the correlation coefficient\n",
    "    corr = group_df[['acceleration', 'horsepower']].corr().min().iloc[0]\n",
    "    n = group_df.shape[0]\n",
    "    ax.annotate(f'r({n}) = {corr:.2f}',\n",
    "        xy=(0.525, 0.9,), xycoords='axes fraction')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na_4NT3L76vO"
   },
   "source": [
    "And offers more control compared with the built-in plotting in pandas, which is much more useful for simple exploration. See [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "_Xrr9AfS8Mtj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633768328044,
     "user_tz": -180,
     "elapsed": 2895,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "99d6002c-e773-47c1-d905-411ed45cc071"
   },
   "source": [
    "ax = mpg.plot.scatter('acceleration', 'horsepower', )\n",
    "\n",
    "correlation_between_acceleration_and_horsepower = mpg[['acceleration', 'horsepower']].corr().min().iloc[0]\n",
    "\n",
    "ax.annotate(f'r({mpg.shape[0]}) = ' +\n",
    "        f\"{correlation_between_acceleration_and_horsepower:.2f}\",\n",
    "        xy=(0.525, 0.9,), xycoords='axes fraction', fontsize=14, c='red'),"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA__xcWyAq4L"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Aggregate the mean and standard deviation of models from USA and Japan, by `origin` and `cylinders`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "MpyU_1HOApeJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633514049790,
     "user_tz": -180,
     "elapsed": 321,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "82a69c40-5c0a-47f2-f26a-ceea409e5f5d"
   },
   "source": [
    "grouped = mpg.loc[mpg['origin'].isin(['usa', 'japan'])].groupby(\n",
    "    ['origin', 'cylinders'])[['mpg', 'horsepower']].agg(['mean', 'std']).round(2)\n",
    "\n",
    "print(grouped.index.levels) # A two-level index\n",
    "grouped.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTqV2KwWDxU0"
   },
   "source": [
    "The result is a `MultiIndex`ed data frame. Here are the basics. See more [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html).\n",
    "\n",
    "----\n",
    "\n",
    "Simple indexing, returning a column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUnSCT7VBhPu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633514240795,
     "user_tz": -180,
     "elapsed": 270,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "d0bf5cd5-4234-41ce-c6ff-57cbb9ab2574"
   },
   "source": [
    "grouped[('mpg', 'mean')]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4G0s3VlA4BL"
   },
   "source": [
    "The indexing with MultiIndex can get complex - here we select the mean of mpg for all cars from Japan, with 3 or 4 cylinders."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2df6QG-3EYKk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633515287101,
     "user_tz": -180,
     "elapsed": 28,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "7073c386-009b-4bdd-8f1b-ecc1cb97b68a"
   },
   "source": [
    "# First we specify the first level of the index, then the second, then the column.\n",
    "# Origin query (First level) > Cylinders query (Second level) > Column query\n",
    "grouped.loc[(('japan'), (3, 4)), ('mpg', 'mean')]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCJdG_8KGhhT"
   },
   "source": [
    "Note that the origin and cylinders columns are now missing from the dataframe, they were turned into row indices (so far we only seen integers). We have shown how we can use them in reindexing operation. But sometimes we would want to return them to the data frame (e.g., if we want to use them on further analysis). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "KSuljaPhGjn1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633515423387,
     "user_tz": -180,
     "elapsed": 435,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "2b07e549-3a91-4436-cfb0-95a90b7dbd1a"
   },
   "source": [
    " # Note that this returns a new dataframe, we can also use `inplace` argument.\n",
    "grouped.reset_index(level='origin')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li2WB2goHBJx"
   },
   "source": [
    "Or skip this in the first place."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "qRnJVgIiHIZP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633515601186,
     "user_tz": -180,
     "elapsed": 305,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "13a26b49-6d8f-4308-da2d-b6d2dfd09179"
   },
   "source": [
    "mpg.groupby(['origin', 'cylinders'], as_index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrZlg8QzHkEg"
   },
   "source": [
    "### Transform\n",
    "\n",
    "Often we would want the aggregation operation to return a data structure that has the same dimensions as the original. For example, when we want to add summary statistics of each group or subject (e.g., think of an experiment with many trials per participant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weight_by_origin_gb = mpg.groupby('origin')['weight'].mean()\n",
    "weight_by_origin_transform = mpg.groupby(\n",
    "        'origin', sort=False)['weight'].transform('mean') # You can also use a function, rather than string - like np.mean, or some custom function\n",
    "\n",
    "print(weight_by_origin_gb.shape,\n",
    "      weight_by_origin_transform.shape, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`assign` is a method that returns a new dataframe with an additional column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg = mpg.assign(weight_by_origin=weight_by_origin_transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oRDn7DcQJ4Cx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633516631895,
     "user_tz": -180,
     "elapsed": 422,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "af66d531-f7c4-4b19-a1e3-befb1f7ac3bf"
   },
   "source": [
    "european_manufacturer = mpg.loc[mpg['origin'] == 'europe']\n",
    "(european_manufacturer['weight_by_origin'] - european_manufacturer['weight']).plot(kind='hist', bins=20)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKrohOakLHmh"
   },
   "source": [
    "Note that we have a couple of `NaN` (used for missing values) on `horsepower`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MEOfcw_lOj4E",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633517460670,
     "user_tz": -180,
     "elapsed": 284,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "71520e33-f38c-4f53-c832-e903a7b171c6"
   },
   "source": [
    "mpg.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlhdefs0Oit8"
   },
   "source": [
    "One way of imputation is to fill the missing values with some cetral tendency measure. We can do it with the mean or median, for example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lWimZLrQf4F"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Fill in the code below, returning the `horsepower` column where missing values will be filled with the dataset median for the column. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lbuurz3lQNzW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633517929627,
     "user_tz": -180,
     "elapsed": 275,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "0b55ceed-d171-456f-afe9-8939255aa17e"
   },
   "source": [
    "mpg['horsepower'].fillna(mpg['horsepower'].agg('median')).isna().any()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJg6EvCFQfQr"
   },
   "source": [
    "If we want to fill the missing values in the column using the mean of a specific group, here is one option."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "hcq3tvKwHeSN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633518383773,
     "user_tz": -180,
     "elapsed": 767,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "05497a67-346e-444f-9fe5-46162aa2c27d"
   },
   "source": [
    "mpg['horsepower'] = mpg['horsepower'].fillna(mpg.groupby('cylinders')['horsepower'].transform(\n",
    "    'mean')).values\n",
    "mpg.describe().round(2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzAxbr5ufIfl"
   },
   "source": [
    "### I / O\n",
    "\n",
    "So far we either created our dataframes by hand, or imported them from a built-in dataset. However, usually you would be working on files.\n",
    "\n",
    "Now is a good time to tell you that Colab runs on a Linux-based machine. As with any computer, we have folders. \n",
    "\n",
    "We can use the exclamation mark to run commands on the shell (\"Command prompt\") of our current machine. In general learning to work with the shell is a very useful skill for anyone working with files and data.\n",
    "\n",
    "Here is the current folder contents, and the contents of the `sample_data` folder that colab offers us."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you are not on Google Colab right now but downloaded the project, run the following code:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "if not any(['COLAB' in k for k in os.environ.keys()]):\n",
    "    os.chdir('..')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ls . # Reveals the files in the current folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mwbvyt1WgiRC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633522180477,
     "user_tz": -180,
     "elapsed": 308,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "725858cb-9871-4eb3-a376-f0e4a4bc95c2"
   },
   "source": [
    "ls \"./sample_data\" # Reveals the files in the sample_data folder"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBpQpjAQgm2g"
   },
   "source": [
    "We see that Colab offers us two famous datasets \"mnist\" and \"california housing\" (if you are not on Colab, you will only see the housing dataset). The files are split into training and testing datasets, so we can easily train a machine learning model to the training set and test on the test set.\n",
    "\n",
    "We will use these files to demonstrate how we read and write data to and from files.\n",
    "\n",
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Fill in the code below to load the california datasets. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xwrvEe9fhHhQ"
   },
   "source": [
    "housing_train = pd.read_csv('sample_data/california_housing_train.csv')\n",
    "housing_test = pd.read_csv('sample_data/california_housing_test.csv')\n",
    "\n",
    "print(housing_train.shape, housing_test.shape, sep='\\n')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YCg98_miIab"
   },
   "source": [
    "Here we combine the two files, by concatenating the two dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bYZ9V9TNiQjD"
   },
   "source": [
    "housing_combined = pd.concat(\n",
    "    [housing_train, housing_test]\n",
    ")\n",
    "print(housing_combined.shape)\n",
    "## Another option would be \n",
    "# df = train.append(test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "929K_bqMjgxX"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Fill in the code below to save the new dataframe into a CSV file named 'california_combined', place it in the same directory as the original files. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SF-h0cu2joA1"
   },
   "source": [
    "housing_combined.to_csv('sample_data/california_combined.csv', index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdSK7rp1jszp"
   },
   "source": [
    "Now let's see if we saved it correctly. \n",
    "\n",
    "In case you are not using Colab, Jupyter Notebook or a similar tool, you might want to use the some module to view files and folders on disk from within Python. One out of many options here would be:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zbjQsrIIkTK6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633523408109,
     "user_tz": -180,
     "elapsed": 284,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "a32c5a59-ffd9-4989-a13e-1f8c09114d14"
   },
   "source": [
    "import glob\n",
    "glob.glob('sample_data/*')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "glob is very useful, and can be used for complex"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glob.glob('sample_data/*_combined.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjOLrxH5loOU"
   },
   "source": [
    "Pandas can work with many [other formats](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) except CSV, like Excel, SPSS, Stata, and more. The process is pretty much the same as we did here.\n",
    "\n",
    "If you want to know more about working with Colab, for example - how to connect your Google Drive to Colab and analyze your own files, see [here](https://colab.research.google.com/notebooks/io.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fQ8M_oCSM1J"
   },
   "source": [
    "### Misc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC49EOZbSccw"
   },
   "source": [
    "Often times we want to view the individual values in a specific column or the whole dataframe. `unique` and `value_counts` are useful here. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lqfx6-NpWb5g"
   },
   "source": [
    "print(mpg['name'].value_counts().head(10),\n",
    "      mpg['name'].unique()[:10], sep='\\n\\n')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh40QA84WxWq"
   },
   "source": [
    "Note that to do the same for a dataframe rather than a series, we will need to use the `apply` method, that iterates over the columns (or rows)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPuG8XprXICG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633519800689,
     "user_tz": -180,
     "elapsed": 277,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "854375e3-c6e2-4234-c254-cf0c422e0747"
   },
   "source": [
    "## Iterating over columns, the default behavior, is equivalent to looping over each column and applying the function to it\n",
    "mpg[['cylinders', 'origin']].apply(lambda s: s.unique())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rxb4xOGHz0Dk"
   },
   "source": [
    "\n",
    "\n",
    "#### Dataframe.query\n",
    "\n",
    "\n",
    "`query` is a row-selection method of pandas dataframes that can be very elegant, especially after long chaining operations.\n",
    "\n",
    "Say we want to take all models weighting more than 2000 which were in made USA. Then we want to aggregate the groups by number of cylinders, and select only those who make less than 25 miles per gallon.\n",
    "\n",
    "Consider the two following options:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "iD_4YQgUpLqY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633507854554,
     "user_tz": -180,
     "elapsed": 284,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "e5132d7c-ec60-4c47-af00-018f72546a12"
   },
   "source": [
    "# This is succint, readable and easy to debug\n",
    "mpg.query('weight > 2000 & origin == \"usa\"'\n",
    "    ).select_dtypes('number').groupby('cylinders').median().query('mpg < 25')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4z07BEPxHOM"
   },
   "source": [
    "#### where and mask\n",
    "\n",
    "`where` is another method, which returns a copy of the dataframe, setting to `NaN` every row or cell that is not True according to the filter expression. This is useful if you want to filter rows or columns but get an object which has the same dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fTOIOxFTxXWe"
   },
   "source": [
    "mpg.where(mpg['name'] == 'buick skylark 320').head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKRN3vCfzY1a"
   },
   "source": [
    "The inverse of `where` is mask."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "69l_DqQJzdP6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633510359956,
     "user_tz": -180,
     "elapsed": 295,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "7164b92b-c7b7-400c-f033-46d26b7d234a"
   },
   "source": [
    "mpg.mask(mpg['name'] == 'buick skylark 320').head(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agA6CeV8lZIa"
   },
   "source": [
    "### Reshaping\n",
    "\n",
    "Reshaping is the act of changing the structure of a dataframe, like turning rows into columns and vice versa (e.g., \"Pivot table\"). \n",
    "\n",
    "As with any task, Pandas offers a variety of reshaping options. Here are the basics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "P_EaKvQJnAxT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633525051909,
     "user_tz": -180,
     "elapsed": 342,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "3101badc-c751-424d-cc8d-094569f7f85e"
   },
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "SqUqyrLInEp3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633525054491,
     "user_tz": -180,
     "elapsed": 433,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "367d2aeb-f02a-4f51-811b-e6f8ec38453f"
   },
   "source": [
    "pivotted = pd.pivot_table(tips, \n",
    "               values=['total_bill', 'tip'], index=['smoker', 'time'], \n",
    "               columns='size',\n",
    "               aggfunc='sum') # Can also be median, your own function, etc.\n",
    "\n",
    "pivotted"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdrHyGzsql0n"
   },
   "source": [
    "Reshaping wide dataframe to long can be achieved usign stack."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "pUYjMDH7qu03",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633525077391,
     "user_tz": -180,
     "elapsed": 288,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "32f581d6-2214-4e40-ed12-85975c3f819f"
   },
   "source": [
    "tips.groupby(['smoker'])[['total_bill', 'tip']].mean().stack().reset_index().rename(\n",
    "    columns={'level_1': 'Variable', 0: 'Mean Value'}\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbgD3jPZp1ix"
   },
   "source": [
    "Crosstabbing is another common operation. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "rBi55bFhp5cF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633524755505,
     "user_tz": -180,
     "elapsed": 308,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "e54ed2e7-a735-4130-fe8f-9bb48429e3a3"
   },
   "source": [
    "pd.crosstab(tips['smoker'], tips['time'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are several ways to remove columns from a dataframe. One is by selection:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.loc[:, ~mpg.columns.isin(['origin'])]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or explicitly:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mpg.drop(['origin'], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDGNzX4gla1u"
   },
   "source": [
    "That's it for pandas, we merely scratched the surface. We didn't cover some very powerful features like windowed operations (e.g., cumulative\\rolling sum), time series and categorical data. To continue on your own, head over [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html).\n",
    "\n",
    "And finally, there are alternatives to Pandas. One particularly interesting one is Polars, which offers different approach to dataframes, which can result in much higher speed and ability to work with very large datasets, compared with Pandas. See [here](https://www.pola.rs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3pxYZF-rxf-"
   },
   "source": [
    "# Seaborn\n",
    "\n",
    "Seaborn is a visualization library (like Matplotlib), but is built on top of Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "trgCuB1m83eQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633771991697,
     "user_tz": -180,
     "elapsed": 2722,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "39954568-f87b-458d-b8a7-0513222f15bc"
   },
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGa-HHqx9JPl"
   },
   "source": [
    "Seaborn offers many types of plots. Most can be drawn straight onto your subplots object and using variables taken straight from a data frame. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "DHm49XrI9Iwx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633530452347,
     "user_tz": -180,
     "elapsed": 949,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "67a18e02-e66a-4806-fb3e-081d177a9447"
   },
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "ax1 = sns.scatterplot(\n",
    "    data=tips, x='total_bill', y='tip', hue='smoker', \n",
    "    ax=axs[0],\n",
    "    legend=None,\n",
    ")\n",
    "\n",
    "ax1.set(xlabel='Total Bill ($)', ylabel='Tip ($)')\n",
    "\n",
    "ax2 = sns.pointplot(\n",
    "    data=tips, x='day', y='tip', hue='smoker',\n",
    "    ax=axs[1],\n",
    "    join=False, dodge=0.3\n",
    ")\n",
    "\n",
    "ax2.set(xlabel='Day', ylabel='Tip ($)')\n",
    "\n",
    "fig.tight_layout()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r18Ke3c6Ack2"
   },
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Generate a figure with subplots in a 3X1 array.\n",
    "Using the `tips` dataset, draw the following from topmost to bottommost.\n",
    "\n",
    "* A horizontal boxplot (`sns.boxplot`) of the number of guests in a party (`size`) on each day. Seperate the boxes into different hues based on the sex of the person paying the waiter.  \n",
    "* A histogram (`sns.histplot`) of the relative size of `tip` to `total_bill`, with the color of the hisograms based on the whether there is a `smoker` in the party. \n",
    "* A line (`sns.lineplot`) showing the trend in `total_bill`' across the values of `size`. Set the style of the lines to whether there is a smoker in the party. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "4vDea8YGBHl8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633772003502,
     "user_tz": -180,
     "elapsed": 2907,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "942c3cd1-ba04-4585-9689-60679b045e52"
   },
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(4, 6))\n",
    "\n",
    "sns.boxplot(ax=axs.flat[0], data=tips, x='day', y='total_bill', hue='smoker')\n",
    "axs.flat[0].legend().remove()\n",
    "\n",
    "sns.histplot(ax=axs.flat[1], data=tips, x=tips['tip'] / tips['total_bill'], \n",
    "             hue='smoker', alpha=0.5)\n",
    "\n",
    "sns.lineplot(data=tips, ax=axs.flat[2], x='size', y='tip', \n",
    "             style='smoker')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToLX4V9AH7Yf"
   },
   "source": [
    "The plots we used so far are axes-level plots. They can either accept an `ax` argument or return a new ax if not given one be to plotted on. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "uEkTveHGJJkT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633533163031,
     "user_tz": -180,
     "elapsed": 972,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "0f4dc694-734d-4479-f7d5-5938d30ba5a5"
   },
   "source": [
    "tips['party_of_two'] = tips['size'] == 2\n",
    "\n",
    "ax = sns.kdeplot(data=tips.query(\"day == 'Fri'\"), x='tip', y='total_bill',\n",
    "                 hue='party_of_two', fill=True, alpha=0.5)\n",
    "\n",
    "# If we want a handle to the Figure object that Seaborn did not give us\n",
    "fig = ax.get_figure()\n",
    "fig.set_facecolor('silver')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Szuv8_IJGTb"
   },
   "source": [
    "\n",
    "\n",
    "Seaborn also can generate figure level plots. \n",
    "\n",
    "They do not accept an `ax` argument, and are drawn into their own object, usually one that inherits properties from the Matplotlib Figure class."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 726
    },
    "id": "KjJT8GC_I0fK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633533277057,
     "user_tz": -180,
     "elapsed": 9629,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "72520257-431e-48f6-dfa4-b8843b075435"
   },
   "source": [
    "pairplot_grid = sns.pairplot(tips.loc[tips['day'].isin(['Thu', 'Sun']), ['total_bill', 'tip', 'smoker']], hue=\"smoker\", )\n",
    "print(pairplot_grid.axes) # Just like a Figure"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZS7RKoogMem"
   },
   "source": [
    "Another illustrative multi-grid plot. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "zW2Y5Fthftly",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633538846421,
     "user_tz": -180,
     "elapsed": 1611,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "cd7f70f6-c23e-4d5c-8188-7b0f0438a990"
   },
   "source": [
    "marginal_hist = sns.jointplot(data=tips.query('day != \"Sun\"'), x='total_bill',\n",
    "                              y='tip', hue='smoker',)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "3oGK38I9geJa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633539033733,
     "user_tz": -180,
     "elapsed": 565,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "78cb2833-0770-44ed-a571-8a92dff3c205"
   },
   "source": [
    "sns.heatmap(tips.select_dtypes('number').corr(), annot=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiD3JRtbfQts"
   },
   "source": [
    "To sum up, most multi grid plots are very useful for exploration of data. \n",
    "\n",
    "One last thing to learn about Seaborn is it's `FacetGrid` object. While offering slightly less control than directly using subplots and looping over groups from a GroupBy operation, it can produce nice graphs quickly. See more [here](https://seaborn.pydata.org/tutorial/axis_grids.html#grid-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "mIuoxmwUheXi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633539342859,
     "user_tz": -180,
     "elapsed": 2418,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "863599c2-8829-425c-8524-e9a696a0a298"
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot') # Set a nice scheme\n",
    "\n",
    "g = sns.FacetGrid(tips, col=\"sex\", row=\"smoker\", hue='day')\n",
    "g.map(sns.scatterplot, \"total_bill\", \"tip\", alpha=.7)\n",
    "g.add_legend()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installing new libraries\n",
    "\n",
    "Before we get to the next section, we need to learn how to install new libraries. Up until now we've used libraries that are either built-in or are already installed in Colab.\n",
    "\n",
    "To install a new library, we use the `pip` command. `pip` is a common package manager in Python. It is used to install, update, and remove packages published on the Python Package Index (PyPI), or shared through other means.\n",
    "\n",
    "Personally, I prefer to use `conda` (see [here](https://anaconda.org/)) to manage my environments and projects, but this is a matter of preference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QTH2ljC5KIs"
   },
   "source": [
    "Let's view the installed packages on the current environment -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, to get a list of the installed packages\n",
    "! pip list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, we have many libraries, but not `pingouin`. Let's install it and get to know it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install pingouin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pingouin\n",
    "\n",
    "There are several libraries in Python that make common statistical tests accessible. We will look mainly at `Pingouin`, as it is highly accessible and includes many tests used frequently in the social sciences.\n",
    "\n",
    "----\n",
    "\n",
    "Pingouin offers many statistical tests, all implemented as functions. These functions receive usually a dataframe, and some other keyword arguments (\"dependent\", \"independent\", etc.). `pingouin` returns the results in a dataframe form."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Often times, you'd want to use a library that you are not familiar with. Usually packages are published on Github, so that's the first place to look for examples and links to the documentation.\n",
    "\n",
    "- Load the `attention` dataset from `Seaborn`. Here's what you need to know about it:\n",
    "\n",
    "    * `subject` is the participant ID.\n",
    "    * `attention` is a manipulation between groups.\n",
    "    * `solutions` is a variable manipulated within groups.\n",
    "    * `score` is the dependent variable on the experiment.\n",
    "\n",
    "- Find Pingouin's Github page.\n",
    "- From there, get to the package documentation.\n",
    "- Find the function that performs a repeated measures ANOVA.\n",
    "- Use it to test the effect of `attention` on `score`, while controlling for `solutions`. Display the partial-et squared effect size.\n",
    "- print the type of the returned object.\n",
    "- print the results of the test, rounded to 3 decimal places."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df = sns.load_dataset('attention')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anova_results = pg.mixed_anova(\n",
    "    data=df,\n",
    "    dv='score',\n",
    "    between='attention',\n",
    "    within='solutions',\n",
    "    subject='subject',\n",
    "    correction=False,\n",
    "    effsize=\"np2\")\n",
    "\n",
    "print(type(anova_results))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(anova_results.round(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### $\\color{dodgerblue}{\\text{Exercise}}$\n",
    "\n",
    "Pingouin has a neat function to plot the trend of a repeated measures design, for individual subjects. Edit the code to:\n",
    " - have `dodgerblue` lines for incrased score, `black` lines for non-changing score, and `crimson` for decreased score.\n",
    " - Format the x-labels to include the means and standard deviation of each level of `solutions`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for ax, (name, group) in zip(axs, df.groupby('attention')):\n",
    "    pg.plot_paired(data=group,\n",
    "                 dv='score', within='solutions', subject='subject', ax=ax,\n",
    "                   colors=['dodgerblue', 'black', 'crimson', ])\n",
    "\n",
    "    ax.set_title(name)\n",
    "\n",
    "    means = group.groupby('solutions')['score'].mean()\n",
    "    sds = group.groupby('solutions')['score'].std()\n",
    "\n",
    "    ax.set_xticklabels([f'{m:.2f} ({s:.2f})' for m, s in zip(means, sds)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use the Penguins dataset from the Seaborn library, and conduct several tests on it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZxPHlSBjUJV"
   },
   "source": [
    "#### t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKIE-G_An94w"
   },
   "source": [
    "After running the ANOVA and finding a significant effect, we'd like to know which groups differ from each other. While `pingouin` does offer a multiple comparison-corrected test, let's use a simple t-test for now, as this is the most common case.\n",
    "\n",
    "We've seen that for the `divided` attention group there mean score of the '3' solutions group is higher than for the '1' solutions group. Let's test this hypothesis. We will use a two-sided hypothesis test, as we don't have a priori expectations about the direction of the effect."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "DRlipN4hoRaM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1633541008069,
     "user_tz": -180,
     "elapsed": 1551,
     "user": {
      "displayName": "Eitan Hemed",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgjTbd1GSnhSQvJi3Wwmdj-WayQxZh7tE-36k6hfg=s64",
      "userId": "11035653591450038643"
     }
    },
    "outputId": "0e6d9910-cb21-4125-864f-fb612855d9cb"
   },
   "source": [
    "gb = df.loc[(df['attention'] == 'divided') & (df['solutions'].isin([1, 3]))].groupby('solutions')\n",
    "\n",
    "level_1, level_3, = gb.get_group(1)['score'], gb.get_group(3)['score']\n",
    "\n",
    "ttest_results = pg.ttest(level_1, level_3, paired=True, alternative='two-sided')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Programmatically format a sentence describing the results of the test."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "terms = ttest_results.iloc[0].to_dict()\n",
    "\n",
    "p_sig = terms['p-val'] < .05\n",
    "\n",
    "'The t-test was {}significant (t({}) = {:.2f}, p={:.3f})'.format(\n",
    "    '' if p_sig else 'not ',\n",
    "    terms['dof'],\n",
    "    terms['T'],\n",
    "    terms['p-val']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Misc."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## robusta\n",
    "\n",
    "Self-promotion time!\n",
    "\n",
    "Related to the previous subject - **[robusta](https://github.com/EitanHemed/robusta)** is a statistical hypothesis testing in Python that I published.  It is still a work in progress, but can be used for most common statistical analysis used in the social sciences. This package is based on [rpy2](https://rpy2.github.io/), an API allowing use R, within Python.\n",
    "\n",
    "This package currently offers Bayesian and frequentist tests which are not available in other Python packages. I chose not to teach you about this package in the workshop, as it is not as mature as Pingouin. However, it is quite feature rich already.\n",
    "\n",
    "Here is a [demo](https://colab.research.google.com/drive/1jmwYpEGcpFr4CF6ZA5HMiQ2LcHbZqzO_?usp=sharing) of the current state, although it will take you less time to set it up locally than to run it on Colab (if you are using Windows).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Local installation of Python\n",
    "\n",
    "This workshop is meant to introduce you into the fundamentals of Python, and using Python for data analysis. It is passed via Colab network mainly for educational purposes, but at some point you will want to install Python locally on your machine, if you intend to use it frequently.\n",
    "\n",
    "Today we will look at one that would fit most academic researchers that intend on using existing Python tools for data analysis (rather than develop their own).\n",
    "\n",
    "JupyterLab is a notebook interface for working with Python (and some other languages, such as R and Julia), and comes with several packages already installed. It is a good starting point for using Python for data analysis, and can be extended with additional packages.\n",
    "\n",
    "**[Download](https://github.com/jupyterlab/jupyterlab-desktop#installation) and install JupyterLab App.**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AI-assisted coding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the past two years or so, AI assisted coding tools were made available to the public, as free or paid services. These tools are based on machine learning models that were trained on large datasets of text and specifically - code. These tools can provide in-notebook or in-IDE code completion, code generation, and more.\n",
    "\n",
    "Personally, I find these tools very useful, and use them frequently. However, they are not perfect. These tools can sometimes produce misleading code - which refers to modules which do not exist, for example. A word of caution - do not run code that you do not inspect closely if it relates to something dramatic (e.g., manipulating files on your system). Always check the validity of non-trivial analysis or plotting you do with it. Having said that, they are getting increasingly better.\n",
    "\n",
    "Using these tools can be helpful especially if you are dealing with a lot of 'boilerplate' code - when you want to perform some task (e.g., filter outliers based on standard scores) which is not very novel, rare or not trivial.\n",
    "\n",
    "Personally, I mostly use Github's [Copilot](https://github.com/features/copilot) on [Pycharm](https://www.jetbrains.com/pycharm/download/) (You can and should get free Pro accounts for both, via your University email). I also sometimes use ChatGPT for non-Python related tasks (e.g., Powershell). There are many tools, and this is a matter of preference, so just explore and see what works for you.\n",
    "\n",
    "Also, although these tools save you some time, you should still learn how to code. These tools are not a replacement for learning how to code, but rather a tool to help you work more efficiently."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
